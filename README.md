# ğŸŒ¤ï¸ Airflow Weather ETL Pipeline

> **Production-ready data engineering pipeline for real-time weather data processing**

[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat-square&logo=apache-airflow)](https://airflow.apache.org/)
[![Astronomer](https://img.shields.io/badge/Astronomer-Runtime%203.0-orange?style=flat-square)](https://www.astronomer.io/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-336791?style=flat-square&logo=postgresql)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker)](https://www.docker.com/)

## ğŸ¯ Overview

A robust **ETL data pipeline** built with Apache Airflow that extracts real-time weather data from Open-Meteo API, transforms it for analysis, and loads it into PostgreSQL. Designed for **production deployment** with Astronomer Runtime and comprehensive testing.

## ğŸ“Š Pipeline Results

![Weather Data Extraction](https://github.com/user-attachments/assets/8b1a067a-9b55-4a2f-8f2f-2e6f1d8a0884)

*Real-time weather data extracted and stored in PostgreSQL*

### âœ¨ Key Features

- **ğŸ”„ Automated ETL** - Daily scheduled weather data processing
- **ğŸŒ API Integration** - Open-Meteo weather service with error handling
- **ğŸ“Š Data Transformation** - Clean, structured weather metrics
- **ğŸ’¾ PostgreSQL Storage** - Persistent data warehouse with timestamps
- **ğŸš€ Astronomer Runtime** - Enterprise-grade Airflow deployment
- **ğŸ§ª Testing Suite** - Comprehensive DAG validation and integrity checks

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[â° Daily Schedule] --> B[ğŸ“¡ Extract Weather API]
    B --> C[ğŸ”„ Transform Data]
    C --> D[ğŸ’¾ Load to PostgreSQL]
    
    E[ğŸŒ Open-Meteo API] --> B
    D --> F[ğŸ“Š Weather Database]
    
    G[ğŸ³ Docker Compose] --> H[ğŸ—„ï¸ PostgreSQL Container]
    I[â˜ï¸ Astronomer Runtime] --> J[âš¡ Airflow Webserver]
    
    style A fill:#e1f5fe
    style F fill:#e8f5e8
    style J fill:#fff3e0
```

## ğŸ› ï¸ Technical Stack

### **Data Engineering**
- **âš¡ Apache Airflow** - Workflow orchestration and scheduling
- **â˜ï¸ Astronomer Runtime 3.0** - Enterprise Airflow distribution
- **ğŸ Python TaskFlow API** - Modern, Pythonic DAG development
- **ğŸ“¡ HTTP Hooks** - Reliable API integration with connection management

### **Data Infrastructure**
- **ğŸ—„ï¸ PostgreSQL** - Production-grade data warehouse
- **ğŸ³ Docker Compose** - Containerized local development
- **ğŸ”— Connection Management** - Secure credential handling
- **ğŸ“Š Data Modeling** - Structured weather metrics schema

### **Location Focus**
- **ğŸ“ Dhaka, Bangladesh** - Latitude: 23.8103, Longitude: 90.4122
- **ğŸŒ Local Weather Monitoring** - Regional climate data collection

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Astronomer CLI (optional for cloud deployment)

### Local Setup

```bash
# Clone repository
git clone https://github.com/Bayzid03/airflow-weather-etl.git
cd airflow-weather-etl

# Start PostgreSQL
docker-compose up -d postgres

# Install Astronomer CLI and start Airflow
astro dev start
```

Access Airflow UI at `http://localhost:8080`

### Production Deployment

```bash
# Deploy to Astronomer Cloud
astro deploy
```

## ğŸ“ Project Structure

```
airflow-weather-etl/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ etlweather.py          # Main ETL pipeline DAG
â”‚   â””â”€â”€ exampledag.py          # Example astronaut data DAG
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ dags/test_dag_example.py  # DAG validation tests
â”œâ”€â”€ docker-compose.yml         # PostgreSQL container setup
â”œâ”€â”€ Dockerfile                 # Astronomer Runtime base
â””â”€â”€ requirements.txt          # Python dependencies
```

## ğŸ”§ Pipeline Details

### **Extract Phase**
```python
# Weather API extraction with error handling
endpoint = f'/v1/forecast?latitude={LATITUDE}&longitude={LONGITUDE}&current_weather=true'
response = http_hook.run(endpoint)
```

### **Transform Phase**
```python
# Data transformation and structuring
transformed_data = {
    'latitude': LATITUDE,
    'longitude': LONGITUDE,
    'temperature': current_weather['temperature'],
    'windspeed': current_weather['windspeed'],
    'winddirection': current_weather['winddirection'],
    'weathercode': current_weather['weathercode']
}
```

### **Load Phase**
```python
# PostgreSQL insertion with schema management
CREATE TABLE IF NOT EXISTS weather_data (
    latitude FLOAT, longitude FLOAT, temperature FLOAT,
    windspeed FLOAT, winddirection FLOAT, weathercode INT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ“Š Data Schema

| Column | Type | Description |
|--------|------|-------------|
| `latitude` | FLOAT | Geographic latitude |
| `longitude` | FLOAT | Geographic longitude |
| `temperature` | FLOAT | Current temperature (Â°C) |
| `windspeed` | FLOAT | Wind speed (km/h) |
| `winddirection` | FLOAT | Wind direction (degrees) |
| `weathercode` | INT | Weather condition code |
| `timestamp` | TIMESTAMP | Data collection time |

## ğŸ¯ Production Features

- **â° Daily Scheduling** - Automated data collection at consistent intervals
- **ğŸ”„ Idempotent Operations** - Safe re-running with catchup disabled
- **ğŸ›¡ï¸ Error Handling** - Robust API failure management
- **ğŸ“ˆ Monitoring** - Airflow UI for pipeline observability
- **ğŸ§ª Testing** - Comprehensive DAG validation suite

## ğŸ§ª Testing

```bash
# Run DAG integrity tests
astro dev pytest tests/

# Validate DAG structure
python -m pytest tests/dags/test_dag_example.py
```

## ğŸŒŸ Future Enhancements

- [ ] **ğŸŒ Multi-location Support** - Global weather data collection
- [ ] **ğŸ“Š Data Visualization** - Grafana dashboards for weather trends
- [ ] **âš¡ Real-time Streaming** - Apache Kafka integration
- [ ] **ğŸ¤– ML Integration** - Weather prediction models
- [ ] **ğŸ“± Alert System** - Weather condition notifications
- [ ] **â˜ï¸ Cloud Storage** - S3/GCS data lake integration

## ğŸ¤ Contributing

Contributions welcome! Focus areas:
- **ğŸ“Š Additional Data Sources** - More weather APIs and metrics
- **ğŸ”§ Pipeline Optimization** - Performance improvements
- **ğŸ“ˆ Monitoring** - Advanced observability features
- **ğŸ§ª Testing** - Enhanced validation coverage

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

---

**Professional data engineering with enterprise-grade tools** ğŸš€ğŸ“Š
